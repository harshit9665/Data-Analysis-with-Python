{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c97648da-ca53-8915-43ac-9c56ea0df123",
    "colab_type": "text",
    "id": "02lNCM7UGw16"
   },
   "source": [
    "# Data PreProcessing\n",
    "\n",
    "\n",
    "I have done data preprocessing on Titanic dataset which consists data of a subset of 891 passengers on the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1d71622d-151a-6d1a-6534-39a31704c78b",
    "colab_type": "text",
    "id": "Zv8Q5pjqGw19"
   },
   "source": [
    "### Preprocessing / Cleaning of data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "7fa1b512-509b-f047-372e-ba6b6dd849c2",
    "colab": {},
    "colab_type": "code",
    "id": "K7ydkpflGw2A"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_data = pd.read_csv('train - train_titanic.csv')\n",
    "train_data1 = pd.read_csv('train - train_titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ll3CscWtGw2b",
    "outputId": "bfb05225-1343-431e-b66e-f80f2bd23b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cb6ecc2e-8f10-d1c6-169f-8d747a66e05d",
    "colab_type": "text",
    "id": "t3fXipbSGw2z"
   },
   "source": [
    "Now, let's take a look at the first few rows of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ef39996e-1c05-2e63-61ca-b28144c01e0a",
    "colab": {},
    "colab_type": "code",
    "id": "Onw4XZLjGw20",
    "outputId": "f87c0cad-b629-405c-dce6-f790262f0be8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31002ed5-0925-d162-b588-6595eacbf68f",
    "colab_type": "text",
    "id": "DJQTSt77Gw29"
   },
   "source": [
    "# A bit about the dataset\n",
    "\n",
    "'Pclass' column contains a number which indicates class of the passenger's ticket:  1 for first class, 2 for second class and 3 for third class. \n",
    "\n",
    "This could function as a proxy for the socio-economic status of the passenger ('upper', 'middle', 'low'). \n",
    "\n",
    "\n",
    "The 'SibSp' column contains the number of siblings + spouses of the passenger also aboard the Titanic;\n",
    "\n",
    "the 'ParCh' column indicates the number of parents + children of the passenger also aboard the Titanic. \n",
    "\n",
    "The 'Ticket' column contains the ticket numbers of passengers (which are not likely to have any predictive power regarding survival);\n",
    "\n",
    "'Cabin' contains the cabin number of the passenger, if he/she had a cabin, and lastly, \n",
    "\n",
    "'Embarked' indicates the port of embarkation of the passenger: **C**herbourg, **Q**ueenstown or **S**outhampton. The meaning of the other columns is clear, I think.\n",
    "\n",
    "Let's check some more info on the DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "a8f8c14a-f0ba-54be-1c2e-bdeb83ab38c9",
    "colab": {},
    "colab_type": "code",
    "id": "CR702QTyGw2_",
    "outputId": "e2b28fcc-0f4c-42cc-c94d-89372ccc48ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "41b720ba-36ea-52f8-4d58-48d5892480c9",
    "colab_type": "text",
    "id": "PZZbfttwGw3F"
   },
   "source": [
    "The DataFrame contains 891 entries in total, with 12 features. Of those 12 features, 10 have non-null values for every entry, and 2 do not: 'Age', which has 714 non-null entries, and 'Cabin', which has only 204 non-null entries (of course, not everyone had a cabin).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgZBlueLGw3H"
   },
   "source": [
    "If we carefully observe the above summary of pandas, there are total 891 rows, Age shows only 714 (means missing), Embarked (2 missing) and Cabin missing a lot as well. Object data types are non-numeric so we have to find a way to encode them to numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XpOOymKWGw3K"
   },
   "source": [
    "# **Dropping Columns which are not useful**\n",
    "\n",
    "Lets try to drop some of the columns which many not contribute much to our machine learning model such as Name, Ticket, Cabin etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_isicKnKGw3K"
   },
   "outputs": [],
   "source": [
    "cols = ['Name', 'Ticket', 'Cabin']\n",
    "train_data = train_data.drop(cols, axis=1)\n",
    "train_data1 = train_data1.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whuqvB3sGw3X",
    "outputId": "8151ca94-c1ea-424b-bc6e-c8e374e7f18a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 62.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lyt6eid2Gw3h"
   },
   "source": [
    "# Dropping rows having missing values\n",
    "Next if we want we can drop all rows in the data that has missing values (NaN). You can do it like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1kBxkfpGw3j"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4J0-Gf7Gw3n",
    "outputId": "6751c401-b026-472b-87d8-b674e411d0a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "PassengerId    712 non-null int64\n",
      "Survived       712 non-null int64\n",
      "Pclass         712 non-null int64\n",
      "Sex            712 non-null object\n",
      "Age            712 non-null float64\n",
      "SibSp          712 non-null int64\n",
      "Parch          712 non-null int64\n",
      "Fare           712 non-null float64\n",
      "Embarked       712 non-null object\n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 55.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uX2u_h1Gw3s"
   },
   "source": [
    "# Problem with dropping rows having missing values\n",
    "After dropping rows with missing values we find that the dataset is reduced to 712 rows from 891, which means we are wasting data. Machine learning models need data for training to perform well. So we preserve the data and make use of it as much as we can. We will see it later.\n",
    "Creating Dummy Variables\n",
    "Now we convert the Pclass, Sex, Embarked to columns in pandas and drop them after conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7RqeedvGw3t"
   },
   "outputs": [],
   "source": [
    "dummies = []\n",
    "\n",
    "cols = ['Pclass', 'Sex', 'Embarked']\n",
    "for col in cols:\n",
    "    dummies.append(pd.get_dummies(train_data1[col]))\n",
    "titanic_dummies = pd.concat(dummies, axis=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjrjxZkDGw3v"
   },
   "source": [
    "# And finally we concatenate to the original dataframe column wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoIupLbEGw3v"
   },
   "outputs": [],
   "source": [
    "train_data1 = pd.concat((train_data1,titanic_dummies), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxtN5Q8SGw3z"
   },
   "source": [
    "Now that we converted Pclass, Sex, Embarked values into columns, we drop the redundant same columns from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHlAXmEFGw30"
   },
   "outputs": [],
   "source": [
    "train_data1 = train_data1.drop(['Pclass', 'Sex', 'Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fElDwhCGw39",
    "outputId": "f1adc863-d54f-4015-a2e5-a7933a61c6a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "1              891 non-null uint8\n",
      "2              891 non-null uint8\n",
      "3              891 non-null uint8\n",
      "female         891 non-null uint8\n",
      "male           891 non-null uint8\n",
      "C              891 non-null uint8\n",
      "Q              891 non-null uint8\n",
      "S              891 non-null uint8\n",
      "dtypes: float64(2), int64(4), uint8(8)\n",
      "memory usage: 48.8 KB\n"
     ]
    }
   ],
   "source": [
    "train_data1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ziG0NzscGw3_"
   },
   "source": [
    "# Taking Care of Missing Data\n",
    "All is good, except age which has lots of missing values. Lets compute a median or interpolate() all the ages and fill those missing age values. Pandas has a interpolate() function that will replace all the missing NaNs to interpolated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnAnpOPMGw3_"
   },
   "outputs": [],
   "source": [
    "train_data1['Age'] = train_data1['Age'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zcLfI8FiGw4E"
   },
   "source": [
    "Now lets observe the data columns. Notice age which is interpolated now with imputed new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pdNKQlqGw4E",
    "outputId": "a89e2323-d47f-4bf1-9467-c04de4616b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "1              891 non-null uint8\n",
      "2              891 non-null uint8\n",
      "3              891 non-null uint8\n",
      "female         891 non-null uint8\n",
      "male           891 non-null uint8\n",
      "C              891 non-null uint8\n",
      "Q              891 non-null uint8\n",
      "S              891 non-null uint8\n",
      "dtypes: float64(2), int64(4), uint8(8)\n",
      "memory usage: 48.8 KB\n"
     ]
    }
   ],
   "source": [
    "train_data1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejRq_FaxGw4H"
   },
   "source": [
    "# Converting the dataframe to numpy\n",
    "\n",
    "Now that we have converted all the data to numeric, its time for preparing the data for machine learning models. \n",
    "\n",
    "This is where scikit and numpy come into play:\n",
    "X = Input set with 14 attributes\n",
    "y = Small y Output, in this case ‘Survived’\n",
    "Now we convert our dataframe from pandas to numpy and we assign input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPe2HXTvGw4I"
   },
   "outputs": [],
   "source": [
    "X = train_data1.values\n",
    "y = train_data1['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3sZH6JLGw4L"
   },
   "source": [
    "X has still Survived values in it, which should not be there. So we drop in numpy column which is the 1st column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nxXxAhcGw4L"
   },
   "outputs": [],
   "source": [
    "X = np.delete(X, 1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePkOfEVXGw4N"
   },
   "source": [
    "# Dividing data set into training set and test set\n",
    "Now that we are ready with X and y, lets split the dataset for 70% Training and 30% test set using scikit model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxGi0V39Gw4N"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data Pre-Processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
